{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非線形なモデルとPreprocessing\n",
    "## 前回行ったこと\n",
    " - 交差検証\n",
    " - グリッドサーチによるハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 今回行うこと\n",
    "- 非線形なモデルを動かす\n",
    "- 特徴ベクトルに対する学習前の処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （復習）データの読み込み・特徴ベクトルの構築\n",
    "one-hotエンコーディングを用いた特徴ベクトルを再び作ります．\n",
    "もう詳しく説明することはしません．\n",
    "全て一つのセルにまとめました．\n",
    "詳細は前回の資料を参照してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データとテストデータの数を取得\n",
      "訓練データ数：12774，テストデータ数：5475\n",
      "[1.67 1.53 1.48 ... 1.5  1.41 1.21]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Colabの場合は以下のコメントアウト外す\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive') # google driveをマウント（＝Colabから使えるようにする）\n",
    "\n",
    "d_train = pd.read_csv(\"data/train.csv\") # 訓練データを読み込む\n",
    "d_test = pd.read_csv(\"data/test.csv\") # テストデータを読み込む\n",
    "# Google Colabの場合\n",
    "#d_train = pd.read_csv(\"drive/My Drive/data/train.csv\") # 訓練データを読み込む．\n",
    "#d_test = pd.read_csv(\"drive/My Drive/data/test.csv\") # テストデータを読み込む．\n",
    "\n",
    "print(\"訓練データとテストデータの数を取得\")\n",
    "n_train = len(d_train)\n",
    "n_test = len(d_test)\n",
    "print(f\"訓練データ数：{n_train}，テストデータ数：{n_test}\")\n",
    "\n",
    "# targetの値\n",
    "y_train = d_train.pop('AveragePrice')\n",
    "y_train = y_train.values # numpyのarrayに変換\n",
    "print(y_train)\n",
    "\n",
    "# one-hot encoding\n",
    "d_train_test = pd.concat([d_train, d_test], axis=0) # 訓練とテストを連結\n",
    "columns_cat = [\"Date\", \"type\", \"region\"] # カテゴリカル変数の列名\n",
    "\n",
    "d_train_test_onehot = pd.get_dummies(d_train_test, columns=columns_cat) # get_dummiesを使ってone-hotエンコーディング\n",
    "d_train_onehot = d_train_test_onehot[:n_train] # d_train_test_onehotの訓練データ部分\n",
    "d_test_onehot = d_train_test_onehot[n_train:] # d_train_test_onehotのテストデータ部分\n",
    "X_train = d_train_onehot.values # np.arrayに変換\n",
    "X_test = d_test_onehot.values  # np.arrayに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いい加減しつこい気もしますが，復習と予測結果の比較のために`LinearRegression`を動かしておきます．\n",
    "ハイパーパラメータ（学習するのではなく，ユーザが決める要素）はここでは`fit_intercept=False`，`normalize=False`とします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.81557459 1.10866466 0.82345937 ... 1.57020038 1.44596604 1.87548053]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # LinearRegressionを使えるようにする\n",
    "lr = LinearRegression(fit_intercept=False, normalize=False) # インスタンスの作成\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_test_lr = lr.predict(X_test)\n",
    "print(y_pred_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非線形なモデルを動かす\n",
    "これまでは線形回帰とリッジ回帰を動かしてきました．\n",
    "これらはどちらもモデルとしては同じで，以下の式で表される線形モデルです：\n",
    "$$y(\\mathbf{x};\\mathbf{w}) = \\mathbf{w}^\\top \\mathbf{x},$$\n",
    "ここで$\\mathbf{w} \\in \\mathbb{R}^d$は学習する重みです（簡単のため，バイアス項（bias term）（あるいは切片（intercept））は無視します．\n",
    "\n",
    "線形モデルは予測モデルの中でも最も単純でわかりやすいものの一つです．\n",
    "しかし，現実の多くの問題はこの単純なモデルで説明することができないことが多いです．\n",
    "例えば，**全ての特徴の値が2倍になった時，線形モデルの予測の値も2倍**になりますが，この性質がどのような問題でも望ましいとは限りません．\n",
    "\n",
    "また，各特徴の要素に対して別々の重みを掛けてその結果を足しているだけで，**特徴同士の相互作用**のようなものを一切考えていません．\n",
    "アボカドの例ですと，例えば，「日付は日付」「場所は場所」で独立に考えています．\n",
    "したがって，線形モデルにおいて，日付がいつであろうとも場所ごとの傾向・バイアスは変わらず，同様にどの場所であろうとも日付ごと（正確には週ごと）の傾向・バイアスは変わりません．\n",
    "しかし，場所によって日付ごと（週ごと）の傾向は変わる可能性があります．\n",
    "例えば（あくまで例えばです），あるアボカドの栽培地域で何らかの天候に関連する災害・被害があったとき，その地域で生産されるアボカドを主に仕入先とする地域ではアボカドの値段に影響があると考えられますが，一方で，異なる地域で栽培されるアボカドを仕入先とする地域では影響を受けない（小さい），といったことがあるかもしれません．\n",
    "しかし，線形モデルではそのようなことを考慮することができません．\n",
    "\n",
    "そこで今回は**非線形なモデル**を使ってみることにします．\n",
    "今回はsklearnによって提供されている非線形なモデルの中から適当に選んで使ってみます．\n",
    "勿論，モデルの持つ非線形性が実際のデータとかけ離れていれば，（妥当なモデルと比べて）上手くいきません．\n",
    "また，非線形なモデルは表現能力（フィッティング能力）が高いことが多く，データが少ない場合は過学習を起こしてしまう可能性もあります．\n",
    "そのことに注意しながら使ってみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多層パーセプトロン（Multi-layer perceptron，MLP）を動かす\n",
    "sklearnには多数の非線形なモデルが実装されています．\n",
    "今回はその中でも，[多層パーセプトロン（Multi-layer perceptron, MLP）](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)を動かしてみます．\n",
    "**MLPはニューラルネットワーク**の一種で，多層のニューラルネットワークの中では最もベーシックなものです．\n",
    "MLPは，数理的には，\n",
    "1. ベクトルに行列を掛ける\n",
    "2. 活性化関数と呼ばれる非線形な関数を噛ませる\n",
    "\n",
    "を繰り返したモデルです．\n",
    "MLPをノード（点）とエッジ（線）を用いてグラフィカルに表現すると，上の2つの演算を繰り返した回数だけ，入力と出力の間に「層」があるように見えます．\n",
    "そのため，上の2つの演算を行う回数を中間層（隠れ層）の数と言い，掛ける行列のことを中間層の重み（行列）と呼びます．\n",
    "中間層の重み行列がMLPの学習するパラメータで，**勾配法**と呼ばれる方法で学習を行います．\n",
    "勾配法（とくに，ここでは誤差関数の最小化を考えることにするので，勾配降下法）は，簡単に説明すると以下のような反復を行うアルゴリズムです：\n",
    "\n",
    "1. パラメータ$\\mathbf{\\Theta}$の初期値を定め，以下の2と3を収束するまで繰り返す．\n",
    "2. 最小化したい関数$L$に対するパラメータの勾配$\\nabla L(\\mathbf{\\Theta})$を計算する．ニューラルネットワークにおいては，この勾配の計算を**誤差逆伝播法（Backpropagation）**と呼ばれる方法で効率よく行う．\n",
    "3. 2で求めた勾配を使ってパラメータを少し動かす．最も単純な方法（＝厳密に単に勾配降下法と言った場合は）では以下のように動かす：\n",
    "    $$\\mathbf{\\Theta} \\leftarrow \\mathbf{\\Theta} - \\eta \\nabla L(\\mathbf{\\Theta}),$$\n",
    "ここで，$\\eta > 0$は学習率やステップサイズと呼ばれるハイパーパラメータで，一回の反復でどの程度パラメータを動かすかを表す．\n",
    "\n",
    "一応簡単に説明しましたが，これでは不十分・わかりにくいように思います．\n",
    "詳細は，例えば[scikit-learnの解説](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#neural-networks-supervised)や，[授業で使っている教科書](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)や，その他多数の書籍やWeb上の記事を参考にしてみてください（「人工知能」の授業で触れているのではないかとも思いますが）．\n",
    "\n",
    "では実際に使ってみます．\n",
    "まずはimportですが，回帰のためのMLPは`NLPRegressor`という名前で，`sklearn.neural_network`の中にあります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではとりあえず，デフォルトのパラメータで使ってみましょう．\n",
    "デフォルト設定のモデルの評価（NOTチューニング）をするために，`cross_validate`をimportします．\n",
    "また，後のため，`GridSearchCV`もimportします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同様に，`cross_validate`で評価をしてみます．\n",
    "`cross_validate`には，学習・評価をしたいモデルとデータ，そして分割数とスコア関数（の名前）を与えるのでした．\n",
    "前回同様，分割数`cv=5`とし，スコア関数は`\"neg_mean_squared_error\"`とします．\n",
    "`cross_validate`を動かすと`scores`という辞書オブジェクトが返ってきます．\n",
    "`\"test_score\"`というキーで交差検証のスコアを取得できるのでした．\n",
    "5回のスコアとその平気を最後にprintします．\n",
    "結局，以下のようになります（前回のほぼコピペ）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交差検証の5回のスコア：[ 2323362.3758501  12500545.84101669  2172804.89995638  5717256.75208008\n",
      "  3599557.01438392]\n",
      "交差検証の平均スコア：5262705.376657436\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor()\n",
    "scores = cross_validate(mlp, X_train, y_train, cv=5, \n",
    "                        scoring=\"neg_mean_squared_error\")\n",
    "print(f\"交差検証の5回のスコア：{-scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{-np.mean(scores['test_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少し待った時間がかかった結果，**トンデモナイスコア**が返ってきました，何だこれ！？\n",
    "過学習にしてもひどいですね．\n",
    "\n",
    "ひどい過学習をしているのかなと思いつつ，一応，**訓練データに対するスコア**を確認してみます．\n",
    "「訓練データに対するスコアを参考にするな」と以前の資料では言ったように思いますが，訓練データに対するスコアは以下のように使うことができます：**訓練データに対するスコアも悪い場合，そもそも学習ができていない**ので，**プログラムの使い方を大きく間違っている**・**そもそもプログラムにバグがある**（今回は考えにくいですが，自身でコアのアルゴリズムを実装した場合はあり得ます）と言ったことを検出できます（つまり，**過学習以前の問題**が起こっている）．\n",
    "この場合，ドキュメントを注意深く読み直す必要があります．\n",
    "\n",
    "`cross_validate`では，`return_train_score`という引数を`True`にすることで，訓練時のスコアも取得できます．\n",
    "`train_score`というキーでアクセスできます（`cross_validate`は辞書型オブジェクトを返すのでしたね）．\n",
    "ちょっと面倒ですが，もう一度交差検証をしてみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交差検証の5回のスコア：[ 1992833.28968998 51036963.73792981  3777703.24596244  2829879.41263\n",
      "  1736710.78743728]\n",
      "交差検証の平均スコア：12274818.094729904\n",
      "交差検証の5回の訓練スコア：[ 2080180.762985   80841653.46863268  4919555.29392469  2283263.25443278\n",
      "  1347239.05828947]\n",
      "交差検証の平均訓練スコア：18294378.367652927\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor()\n",
    "scores = cross_validate(mlp, X_train, y_train, cv=5, \n",
    "                        scoring=\"neg_mean_squared_error\",\n",
    "                        return_train_score=True)\n",
    "print(f\"交差検証の5回のスコア：{-scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{-np.mean(scores['test_score'])}\")\n",
    "\n",
    "print(f\"交差検証の5回の訓練スコア：{-scores['train_score']}\")\n",
    "print(f\"交差検証の平均訓練スコア：{-np.mean(scores['train_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "……ということで[ドキュメント](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)を読みに行きましょう．\n",
    "ハイパーパラメータの数に圧倒されるかもしれませんが，どうか諦めないでください．\n",
    "いくつかのパラメータに関して簡単に見ていきます．\n",
    "- `hidden_layer_sizes`：intのタプル（リストのようなもの），隠れ層（中間層）のユニット数．例えば，`(100, 50, 20)`を指定すると，中間層の数が3つで，入力に近い方から順に中間層のユニット数が100, 50, 20となる．中間層の数は「行列を掛ける」「活性化関数を噛ませる」回数に対応し，ユニット数は行列を掛けた後のベクトルの要素数に対応します．つまり，ネットワークの構造（深さと広さ）を定めるものです．\n",
    "- `activation`：string，活性化関数（行列を掛けた後に作用させる非線形な関数）．ここでは，\n",
    "  - `\"identity\"`：恒等関数（$g(x)=x$）\n",
    "  - `\"logistic\"`：ロジスティックシグモイド関数（$g(x)=1 / [1+\\exp (-x)]$）\n",
    "  - `\"tanh\"`：ハイパボリックタンジェント\n",
    "  - `\"relu\"`：ランプ関数（$g(x)= \\max (0, x)$)\n",
    "  \n",
    "  の4つを選択できる．デフォルトは`\"relu\"`．\n",
    "- `solver`：string，最適化手法．MLPは勾配法で最適化すると言いましたが，一口に勾配法と言っても実は色々あり，ここでは，\n",
    "  - `\"lbfgs\"`：準ニュートン法（quasi-newton method）と呼ばれる方法の一種．ヘッセ行列（＝二回微分）を近似し，上手く用いる．\n",
    "  - `\"sgd\"`：確率的勾配降下法（stochastic gradient descent, SGD），一回の反復に全てのデータではなく一部のデータのみを用いる．\n",
    "  - `\"adam\"`：SGDの一種で，勾配の使い方・ステップサイズに色々と工夫が施されている．\n",
    "  \n",
    "  の3つを指定できる．デフォルトは`\"adam\"`．\n",
    "- `alpha`：float，正則化項の強さ（Ridge回帰と同じ）．\n",
    "- `batch_size`：int， SGD・Adamにおいて，一回の反復で用いるデータの数．\n",
    "- `learning_rate_init`：float，初期学習率．デフォルトは`0.001`．\n",
    "- `max_iter`：int，最大反復回数．デフォルトは200.\n",
    "- `beta_1`, `beta_2`：float，`\"Adam\"`のハイパーパラメータ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちょっと疲れたのでこの辺にしておきます．\n",
    "まず，最初の`hidden_layer_sizes`と`activation`は，ネットワークの構造を決めるものなので性能に直結しそうですね．\n",
    "また，最適化アルゴリズムの選択および最適化アルゴリズムのハイパーパラメータの選択も非常に重要です．\n",
    "ここではとりあえず，他のハイパーパラメータはそのままで，先程試した`\"relu\"`以外の活性化関数を用いて交差検証で評価してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "活性化関数：identity\n",
      "交差検証の5回のスコア：[7.50153718e+05 7.22792391e+01 1.12904578e+08 5.35382391e+06\n",
      " 3.02602088e+07]\n",
      "交差検証の平均スコア：29853767.343822487\n",
      "\n",
      "活性化関数：logistic\n",
      "交差検証の5回のスコア：[0.12962243 0.1218483  0.12786178 0.12736871 0.12544793]\n",
      "交差検証の平均スコア：0.12642983042065764\n",
      "\n",
      "活性化関数：tanh\n",
      "交差検証の5回のスコア：[0.12666944 0.11986777 0.12991164 0.12385399 0.12259586]\n",
      "交差検証の平均スコア：0.12457974034194799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for activation in [\"identity\", \"logistic\", \"tanh\"]:\n",
    "    print(f\"活性化関数：{activation}\")\n",
    "    mlp = MLPRegressor(activation=activation)\n",
    "    scores = cross_validate(mlp, X_train, y_train, cv=5, \n",
    "                            scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"交差検証の5回のスコア：{-scores['test_score']}\")\n",
    "    print(f\"交差検証の平均スコア：{-np.mean(scores['test_score'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果が出てきました！\n",
    "まだお世辞にも良いとは言えませんが，**活性化関数が`\"logistic\"`・`\"tanh\"`のときは異常な結果にはならない**ということがわかりました．\n",
    "\n",
    "ここで，この4種類の活性化関数のグラフを作ってみます（横軸が入力で，縦軸が関数の値）．\n",
    "様々な可視化は次回行いますが，とりあえず以下のセルを動かすとグラフが出てきます．\n",
    "グラフの作り方についてもう少しきちんと知りたい方は，day6_matplotlib.ipynbを見る・matplotlibで調べる等してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jupyter lab/notebookの時のコマンド\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "x = 4*np.arange(100) / 100 - 2.0\n",
    "plt.plot(x, x, label=\"identity\") # identity\n",
    "plt.plot(x, 1.0 / (1.0 + np.exp(-x)), label=\"logistic\") # logistic\n",
    "plt.plot(x, np.tanh(x), label=\"tanh\") # tanh\n",
    "plt.plot(x, np.maximum(x, 0), label=\"relu\") # relu\n",
    "plt.legend(fontsize=12, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "異常な結果となった`\"identity\"`と`\"relu\"`は非有界（=関数の値がどこまでも大きくなる or 小さくなる）ですが，（お世辞にも良い結果ではないですが）正常に働いた`\"logistic\"`と`\"tanh\"`は有界(前者は$(0, 1)$，後者は$(-1, 1)$)です．\n",
    "そのため，以下のようなことが起こっているのではないかと考えられます：**活性化関数に通す前の中間層の値が非常に大きくなってしまっているのではないか？**\n",
    "\n",
    "活性化関数に通す前の値は，「入力ベクトルと重み行列の積」によって計算されます．\n",
    "したがって，特徴ベクトルの値が大きい場合，中間層の値が非常に大きくなってしまう可能性があります．\n",
    "特徴ベクトルの値をちょっと思い出してみます．\n",
    "one-hotエンコーディングによって作られた部分は0か1でした．\n",
    "各サイズで売れた数を表す部分は，かなり大きな数字が入っていたような記憶があると思います．\n",
    "ちょっと見てみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date         4046         4225       4770  Small Bags  \\\n",
      "0      2017-04-23      1121.34      5184.26       0.00      888.21   \n",
      "1      2017-09-17   1582315.47   1095433.56   47072.46   863081.25   \n",
      "2      2017-11-05       141.41       794.48       0.00     5320.50   \n",
      "3      2016-01-24      5289.88       111.58       0.00     5096.27   \n",
      "4      2018-01-28  14551799.50  12119884.61  575974.74  9749412.19   \n",
      "...           ...          ...          ...        ...         ...   \n",
      "12769  2015-07-12      1639.19        49.62       0.00     3592.55   \n",
      "12770  2016-01-31      8791.51     58433.15       0.00     6581.99   \n",
      "12771  2018-01-21       613.65      1852.11       0.00     4083.63   \n",
      "12772  2016-07-31       553.48         5.70       0.00     4514.72   \n",
      "12773  2015-03-15    156506.22    160239.43   17300.74    58756.28   \n",
      "\n",
      "       Large Bags  XLarge Bags          type            region  \n",
      "0         2717.94         0.00       organic          LasVegas  \n",
      "1       591149.15      2174.92  conventional              West  \n",
      "2         1452.69         0.00       organic      Indianapolis  \n",
      "3            6.67         0.00       organic           Houston  \n",
      "4      3041125.42    133444.38  conventional           TotalUS  \n",
      "...           ...          ...           ...               ...  \n",
      "12769        0.00         0.00       organic           Orlando  \n",
      "12770    15767.67         0.00       organic        GreatLakes  \n",
      "12771     2428.58         0.00       organic          Columbus  \n",
      "12772      113.33         0.00       organic  NewOrleansMobile  \n",
      "12773        0.00         0.00  conventional          Portland  \n",
      "\n",
      "[12774 rows x 9 columns]\n",
      "22743616.17\n"
     ]
    }
   ],
   "source": [
    "print(d_train)\n",
    "print(np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大で8ケタの非常に大きな値が入っており，先程述べていたことが起こっている可能性が高そうに思えてきます．\n",
    "また，そもそも，特徴の値の最大値と最小値の範囲が，各特徴毎に大きく異なるというのは問題となることがあります．\n",
    "線形モデルの例を考えてみます．\n",
    "one-hotエンコーディングされたある特徴（たとえば，`\"region_LasVegas\"`）の重みを$w_j$，あるサイズとして売れた数（たとえば，`4046`）に関する重みを$w_i$とし，$w_j=w_i=0.01$であるとします．\n",
    "このとき，one-hotエンコーディングされたある特徴の重み$w_j=0.01$であることに大きな問題はなさそうです：$x_j$は最大でも$1$なので，$x_j=0$の場合と比較しても予測の値が$0.01$増えるだけです．\n",
    "一方で，売れた数に関する重み**$w_i=0.01$は問題が起こります**：$x_i$の値が，例えば上で出ている最大値`22743616.17`のとき，$x_i=0$の場合と比較して，**予測の値がおよそ227436も増えてしまいます**．\n",
    "つまり，各特徴に対応するパラメータ（上の例では，$w_j$や$w_i$）のスケールは，その特徴のスケールに応じて適切なものになってなければなりません．\n",
    "\n",
    "[sklearnのニューラルネットワークに関する解説](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use)を見てみましょう．\n",
    "次のように書いてあります：\n",
    "\n",
    "- \"Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization.\"\n",
    "\n",
    "ようするに，**MLPは特徴のスケールに影響を受けやすいので，そこらへんはどうにかしなさい（例えば，各特徴の値が$[0, 1]$や$[-1, 1]$の範囲に入るようにであったり，平均が0で分散が1になるようにしなさい）**と言っています．\n",
    "このように，学習アルゴリズムに入れる前に，特徴量に対して何らかの変換を施すことを**前処理（preprocessing）**と言います（one-hotエンコーディングも前処理の一部であると言えるでしょう）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn.preprocessing`：sklearnの機能を使って特徴量のスケールを揃える\n",
    "\n",
    "さて，それでは上で言われているように，特徴ベクトルのスケールを揃えてみましょう．\n",
    "今回は各特徴量を`[0, 1]`の範囲に（=最小値が0で最大値が1になるように）スケーリングします．\n",
    "numpyの演算を使うことでも比較的簡単にできますが，ここではsklearnの機能を使うことにします．\n",
    "\n",
    "sklearnには`sklearn.preprocessing`というモジュールがあり，このモジュールの中に様々な前処理のための関数・クラスが用意されています．\n",
    "今回は，**最大値と最小値を揃えるスケーリング**を行いたいわけですが，これは`sklearn.preprocessing`の中の`MinMaxScaler`によって行うことができます．\n",
    "\n",
    "そこで，今回のQuizです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1\n",
    "[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)を使って，各特徴の値を[0,1]の範囲にスケーリングした訓練データ`X_train_scaled`を作成し，`X_train_scaled`を用いて`MLPRegressor()`の交差検証を行してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交差検証の5回のスコア：[0.03407623 0.03111196 0.03084854 0.02956114 0.03339093]\n",
      "交差検証の平均スコア：0.031797759577266514\n",
      "交差検証の5回の訓練スコア：[0.00243832 0.00273227 0.0021143  0.00203041 0.00230025]\n",
      "交差検証の平均訓練スコア：0.0023231097986461864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 以下を埋める\n",
    "\n",
    "\n",
    "X_train_scaled =  # ここを埋める\n",
    "\n",
    "# モデルを作成し，交差検証で評価\n",
    "mlp = MLPRegressor()\n",
    "scores = cross_validate(mlp, X_train_scaled, y_train, cv=5, \n",
    "                        scoring=\"neg_mean_squared_error\",\n",
    "                        return_train_score=True)\n",
    "print(f\"交差検証の5回のスコア：{-scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{-np.mean(scores['test_score'])}\")\n",
    "\n",
    "print(f\"交差検証の5回の訓練スコア：{-scores['train_score']}\")\n",
    "print(f\"交差検証の平均訓練スコア：{-np.mean(scores['train_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信じられないほど改善しました！\n",
    "しかもまだ細かい交差検証はしていませんから，更に性能の向上を見込めます．\n",
    "\n",
    "交差検証をして良いパラメータを定めてみましょう．\n",
    "前回の復習も兼ねて，続けてクイズです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2\n",
    "`X_train_scaled`を訓練データの入力として，`MLPRegressor`のハイパーパラメータを`GridSearchCV`によってチューニングしてください．\n",
    "ここで，以下の2つのパラメータを次で示す範囲でチューニングすること：\n",
    "- `hidden_layer_sizes`：(1)中間層が一つでユニット数が100 (2)中間層が2つでユニット数がそれぞれ80\n",
    "- `activation`：(1) \"logistic\" (2) \"tanh\" (3) \"relu\"\n",
    "\n",
    "また，計算時間の削減のため反復数`max_iter`は100とし，乱数の初期SEEDを定める`random_state`は765としてください．交差検証の分割数は5，スコア関数は`\"neg_mean_squared_error\"`とすること．\n",
    "そして最後に，最も良かったハイパーパラメータの組と，その時の交差検証のスコアを`print`してください．\n",
    "その際に，交差検証のスコアは正負を反転させて平均二乗誤差にしてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': (80, 80)}\n",
      "0.024242445515821536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = # ここを埋める\n",
    "params_grid = {} # ここを埋める\n",
    "# 以下を埋める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も良かったハイパーパラメータとその時のスコアについて，TFの環境では以下の結果が得られました：\n",
    "\n",
    "`{'activation': 'tanh', 'hidden_layer_sizes': (80, 80)}`\n",
    "\n",
    "`0.024242445515821536`\n",
    "\n",
    "この結果で得られたベストなモデルを使って予測結果を提出すると良いかもしれません．\n",
    "その際，**テストデータの変換を行うのを忘れる・変換の仕方を誤る**と，ひどいスコアとなってしまうためご注意ください．\n",
    "なお，上のチューニングはかなり粗く・雑に行っているので，より丁寧に行うことでより良いスコアが出る可能性は高いです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "- 多層パーセプトロン（MLP)：ニューラルネットワークの一種．（非線形な活性化関数を使った場合）非線形なモデルで，特徴ベクトルのスケールに影響を強く受ける．\n",
    "- 前処理のための関数やクラスは`sklearn.preprocessing`にある．最大値と最小値のスケーリングは`MinMaxScaler`で行うことができる．\n",
    "\n",
    "今回用いた`MinMaxScaler`以外にも前処理のクラス・関数は多数あるので，それらについても調べてみる・使ってみると良いかもしれません．\n",
    "また，具体的に名前を列挙することはしませんが，非線形なモデルは`MLPRegressor`以外にも多数あります．\n",
    "その中には，特徴ベクトルのスケールの影響を受けにくく，使いやすいモデルもあります．\n",
    "また，興味深いことに，カテゴリカル変数をそのまま扱える手法もあります（残念ながらsklearnの実装ではそうなっておらず，その手法に特化したライブラリを使う必要がありますが）．\n",
    "「どのような特徴を作るか」「どのような変換を施すか」「どのようなモデルを使うか」「どのようなハイパーパラメータにするか」を考えると，できることは山ほどあるので，是非色々試してみてください．\n",
    "\n",
    "さらに，ここ10年弱の深層学習ブームにより，ニューラルネットワークのライブラリが多数開発されています．\n",
    "それらを用いることでより自由に・柔軟にニューラルネットワークを（MLPを）構築することができます．\n",
    "それらについても興味があれば調べてみると良いかもしれません．\n",
    "\n",
    "今回は，予測モデルを構築する前の処理として，スケーリングを取り上げました．\n",
    "それ以外にも，例えば\n",
    "- 特徴選択（feature selection）：元の特徴量からいくつかの特徴量を選ぶ (特徴選択で作られた低次元ベクトルは，元の特徴ベクトルの部分ベクトル)\n",
    "- 特徴抽出（feature extraction)：元の特徴量を用いて新しく（低次元の）特徴量を作り出す(元の特徴ベクトルの部分ベクトルとは限らない）\n",
    "\n",
    "等の処理を行うと，性能が向上することもあります．\n",
    "これらはsklearnでは[sklearn.feature_selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)や[sklearn.decomposition](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)に実装されています．\n",
    "余裕がある方は試してみると良いかもしれません．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from sklearn.preprocessing import MinMaxScaler`で使えるようになります．\n",
    "`MinMaxScaler`は，標準では[0,1]にスケーリングするため，特に引数の設定をすることなくインスタンスを作成します．\n",
    "ドキュメントを読んでみると分かりますが，`fit`メソッドで各特徴量の最大値と最小値を計算し，`transform`メソッドで変換を施した行列を返します．\n",
    "そのため，以下のようになります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 以下を埋める\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) # ここを埋める\n",
    "\n",
    "# モデルを作成し，交差検証で評価\n",
    "mlp = MLPRegressor()\n",
    "scores = cross_validate(mlp, X_train_scaled, y_train, cv=5, \n",
    "                        scoring=\"neg_mean_squared_error\",\n",
    "                        return_train_score=True)\n",
    "print(f\"交差検証の5回のスコア：{-scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{-np.mean(scores['test_score'])}\")\n",
    "\n",
    "print(f\"交差検証の5回の訓練スコア：{-scores['train_score']}\")\n",
    "print(f\"交差検証の平均訓練スコア：{-np.mean(scores['train_score'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': (80, 80)}\n",
      "0.024242445515821536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyohei/.local/share/virtualenvs/pipenv3.8.1-zyzkCb9a/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=100, random_state=765) # ここを埋める\n",
    "params_grid = {\n",
    "    \"hidden_layer_sizes\": [(100, ), (80, 80)],\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],} # ここを埋める\n",
    "# 以下を埋める\n",
    "cv = GridSearchCV(mlp, param_grid=params_grid, cv=5, scoring=\"neg_mean_squared_error\") # \n",
    "cv.fit(X_train_scaled, y_train)\n",
    "print(cv.best_params_) # 最も良かったハイパーパラメータを見てみる\n",
    "print(-cv.best_score_) # 最も良かったハイパーパラメータの時のスコアを見てみる．わかりやすさのため符号は反転する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
