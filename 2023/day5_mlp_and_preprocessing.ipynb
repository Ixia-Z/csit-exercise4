{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPモデルとPreprocessing\n",
    "## 前回行ったこと\n",
    " - 交差検証\n",
    " - グリッドサーチによるハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 今回行うこと\n",
    "- MLP（多層パーセプトロン）モデルを動かす\n",
    "- 特徴ベクトルに対する学習前の処理\n",
    "- 付録：EDA（Exploratory Data Analysis, 探索的データ分析）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （復習）データの読み込み・特徴ベクトルの構築\n",
    "one-hotエンコーディングを用いた特徴ベクトルを再び作ります．\n",
    "もう詳しく説明することはしません．\n",
    "全て一つのセルにまとめました．\n",
    "詳細は前回の資料を参照してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Google Colabの場合\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive') # google driveをマウント（＝Colabから使えるようにする）\n",
    "d_train = pd.read_csv(\"drive/My Drive/data/train.csv\") \n",
    "d_test = pd.read_csv(\"drive/My Drive/data/test.csv\") \n",
    "\n",
    "# 自身のPython環境で動かしている場合，コメントアウトを外す\n",
    "#d_train = pd.read_csv(\"data/train.csv\")\n",
    "#d_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(\"訓練データとテストデータの数を取得\")\n",
    "n_train = len(d_train)\n",
    "n_test = len(d_test)\n",
    "print(f\"訓練データ数：{n_train}，テストデータ数：{n_test}\")\n",
    "\n",
    "# targetの値\n",
    "y_train = d_train.pop('stroke')\n",
    "y_train = y_train.values # numpyのarrayに変換\n",
    "print(y_train)\n",
    "\n",
    "# one-hot encoding\n",
    "d_train_test = pd.concat([d_train, d_test], axis=0) # 訓練とテストを連結\n",
    "columns_cat = [\"gender\",\"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\"] # カテゴリカル変数の列名\n",
    "d_train_test = pd.get_dummies(d_train_test, columns=columns_cat) # get_dummiesを使ってone-hotエンコーディング\n",
    "d_train_test.pop(\"bmi\") # 今回はbmiデータを使わず，捨てる\n",
    "d_train = d_train_test[:n_train] # d_train_test_onehotの訓練データ部分\n",
    "d_test = d_train_test[n_train:] # d_train_test_onehotのテストデータ部分\n",
    "\n",
    "X_train = d_train.values # np.arrayに変換\n",
    "X_test = d_test.values  # np.arrayに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いい加減しつこい気もしますが，復習と予測結果の比較のために`LogisticRegression`を動かしておきます．\n",
    "ハイパーパラメータ（学習するのではなく，ユーザが決める要素）はここでは`fit_intercept=False`，`class_weight='balanced'`とします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # LogisticRegressionを使えるようにする\n",
    "lr = LogisticRegression(fit_intercept=False, class_weight='balanced') # インスタンスの作成\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_test_lr = lr.predict_proba(X_test)[:,1]\n",
    "print(y_pred_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多層パーセプトロン（Multi-layer perceptron，MLP）を動かす\n",
    "今回は，[多層パーセプトロン（Multi-layer perceptron, MLP）](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)を動かしてみます．\n",
    "**MLPはニューラルネットワーク**の一種で，多層のニューラルネットワークの中では最もベーシックなものです．\n",
    "MLPは，数理的には，\n",
    "1. ベクトルに行列を掛ける\n",
    "2. 活性化関数と呼ばれる非線形な関数を噛ませる\n",
    "\n",
    "を繰り返したモデルです．\n",
    "MLPをノード（点）とエッジ（線）を用いてグラフィカルに表現すると，上の2つの演算を繰り返した回数だけ，入力と出力の間に「層」があるように見えます．\n",
    "そのため，上の2つの演算を行う回数を中間層（隠れ層）の数と言い，掛ける行列のことを中間層の重み（行列）と呼びます．\n",
    "中間層の重み行列がMLPの学習するパラメータで，**勾配法**と呼ばれる方法で学習を行います．\n",
    "勾配法（とくに，ここでは誤差関数の最小化を考えることにするので，勾配降下法）は，簡単に説明すると以下のような反復を行うアルゴリズムです：\n",
    "\n",
    "1. パラメータ$\\mathbf{\\Theta}$の初期値を定め，以下の2と3を収束するまで繰り返す．\n",
    "2. 最小化したい関数$L$に対するパラメータの勾配$\\nabla L(\\mathbf{\\Theta})$を計算する．ニューラルネットワークにおいては，この勾配の計算を **誤差逆伝播法（Backpropagation）** と呼ばれる方法で効率よく行う．\n",
    "3. 2で求めた勾配を使ってパラメータを少し動かす．最も単純な方法（＝厳密に単に勾配降下法と言った場合は）では以下のように動かす：\n",
    "    $$\\mathbf{\\Theta} \\leftarrow \\mathbf{\\Theta} - \\eta \\nabla L(\\mathbf{\\Theta}),$$\n",
    "ここで，$\\eta > 0$は学習率やステップサイズと呼ばれるハイパーパラメータで，一回の反復でどの程度パラメータを動かすかを表す．\n",
    "\n",
    "一応簡単に説明しましたが，これでは不十分・わかりにくいように思います．\n",
    "詳細は，例えば[scikit-learnの解説](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#neural-networks-supervised)や，[授業で使っている教科書](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)や，その他多数の書籍やWeb上の記事を参考にしてみてください（「人工知能」の授業で触れているのではないかとも思いますが）．\n",
    "\n",
    "では実際に使ってみます．\n",
    "まずはimportですが，分類のためのMLPは`MLPClassifier`という名前で，`sklearn.neural_network`の中にあります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではとりあえず，デフォルトのパラメータで使ってみましょう．\n",
    "デフォルト設定（チューニングをしていない）のモデルの評価をするために，`cross_validate`をimportします．\n",
    "また，後のため，`GridSearchCV`もimportします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同様に，`cross_validate`で評価をしてみます．\n",
    "`cross_validate`には，学習・評価をしたいモデルとデータ，そして分割数とスコア関数（の名前）を与えるのでした．\n",
    "前回同様，分割数`cv=5`とし，スコア関数は`\"arc_roc\"`とします．\n",
    "`cross_validate`を動かすと`scores`という辞書オブジェクトが返ってきます．\n",
    "`\"test_score\"`というキーで交差検証のスコアを取得できるのでした．\n",
    "5回のスコアとその平均を最後に`print`します．\n",
    "結局，以下のようになります（前回のほぼコピペ）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "scores = cross_validate(mlp, X_train, y_train, cv=5, \n",
    "                        scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"交差検証の5回のスコア：{scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{np.mean(scores['test_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少し待った時間がかかった結果，**トンデモナイスコア**が返ってきました，何だこれ！？\n",
    "過学習にしてもひどいですね．\n",
    "\n",
    "ひどい過学習をしているのかなと思いつつ，一応，**訓練データに対するスコア**を確認してみます．\n",
    "「訓練データに対するスコアを参考にするな」と以前の資料では言ったように思いますが，訓練データに対するスコアは以下のように使うことができます：**訓練データに対するスコアも悪い場合，そもそも学習ができていない**ので，**プログラムの使い方を大きく間違っている**・**そもそもプログラムにバグがある**（今回は考えにくいですが，自身でコアのアルゴリズムを実装した場合はあり得ます）と言ったことを検出できます（つまり，**過学習以前の問題**が起こっている）．\n",
    "この場合，ドキュメントを注意深く読み直す必要があります．\n",
    "\n",
    "`cross_validate`では，`return_train_score`という引数を`True`にすることで，訓練時のスコアも取得できます．\n",
    "`train_score`というキーでアクセスできます（`cross_validate`は辞書型オブジェクトを返すのでしたね）．\n",
    "ちょっと面倒ですが，もう一度交差検証をしてみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "scores = cross_validate(mlp, X_train, y_train, cv=5, \n",
    "                        scoring=\"roc_auc\",\n",
    "                        return_train_score=True)\n",
    "print(f\"交差検証の5回のスコア：{scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{np.mean(scores['test_score'])}\")\n",
    "\n",
    "print(f\"交差検証の5回の訓練スコア：{scores['train_score']}\")\n",
    "print(f\"交差検証の平均訓練スコア：{np.mean(scores['train_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "……ということで[ドキュメント](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)を読みに行きましょう．\n",
    "ハイパーパラメータの数に圧倒されるかもしれませんが，どうか諦めないでください．\n",
    "いくつかのパラメータに関して簡単に見ていきます．\n",
    "- `hidden_layer_sizes`：intのタプル（リストのようなもの），隠れ層（中間層）のユニット数．例えば，`(100, 50, 20)`を指定すると，中間層の数が3つで，入力に近い方から順に中間層のユニット数が100, 50, 20となる．中間層の数は「行列を掛ける」「活性化関数を噛ませる」回数に対応し，ユニット数は行列を掛けた後のベクトルの要素数に対応します．つまり，ネットワークの構造（深さと広さ）を定めるものです．\n",
    "- `activation`：string，活性化関数（行列を掛けた後に作用させる非線形な関数）．ここでは，\n",
    "  - `\"identity\"`：恒等関数 $g(x)=x$\n",
    "  - `\"logistic\"`：ロジスティックシグモイド関数 $g(x)=1 / (1+e^{-x})$\n",
    "  - `\"tanh\"`：ハイパボリックタンジェント $g(x)= (e^x-e^{-x}) / (e^x+e^{-x})$\n",
    "  - `\"relu\"`：ランプ関数 $g(x)= \\max (0, x)$\n",
    "  \n",
    "  の4つを選択できる．デフォルトは`\"relu\"`．\n",
    "- `solver`：string，最適化手法．MLPは勾配法で最適化すると言いましたが，一口に勾配法と言っても実は色々あり，ここでは，\n",
    "  - `\"lbfgs\"`：準ニュートン法（quasi-newton method）と呼ばれる方法の一種．ヘッセ行列（＝二回微分）を近似し，上手く用いる．\n",
    "  - `\"sgd\"`：確率的勾配降下法（stochastic gradient descent, SGD），一回の反復に全てのデータではなく一部のデータのみを用いる．\n",
    "  - `\"adam\"`：SGDの一種で，勾配の使い方・ステップサイズに色々と工夫が施されている．\n",
    "  \n",
    "  の3つを指定できる．デフォルトは`\"adam\"`．\n",
    "- `alpha`：float，正則化項の強さ．\n",
    "- `batch_size`：int， SGD・Adamにおいて，一回の反復で用いるデータの数．\n",
    "- `learning_rate_init`：float，初期学習率．デフォルトは`0.001`．\n",
    "- `max_iter`：int，最大反復回数．デフォルトは`200`.\n",
    "- `beta_1`, `beta_2`：float，`\"Adam\"`のハイパーパラメータ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちょっと疲れたのでこの辺にしておきます．\n",
    "まず，最初の`hidden_layer_sizes`と`activation`は，ネットワークの構造を決めるものなので性能に直結しそうですね．\n",
    "また，最適化アルゴリズムの選択および最適化アルゴリズムのハイパーパラメータの選択も非常に重要です．\n",
    "ここではとりあえず，他のハイパーパラメータはそのままで，先程試した`\"relu\"`以外の活性化関数を用いて交差検証で評価してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation in [\"identity\", \"logistic\", \"tanh\"]:\n",
    "    print(f\"活性化関数：{activation}\")\n",
    "    mlp = MLPClassifier(activation=activation)\n",
    "    scores = cross_validate(mlp, X_train, y_train, cv=5, \n",
    "                            scoring=\"roc_auc\")\n",
    "    print(f\"交差検証の5回のスコア：{scores['test_score']}\")\n",
    "    print(f\"交差検証の平均スコア：{np.mean(scores['test_score'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果が出てきました！\n",
    "活性化関数の違いによって予測結果に少し影響が出ていることがわかりました．特に，活性化関数が`\"logistic\"`，`\"tanh\"`の時の性能は，活性化関数が`\"identity\"`，`\"relu\"`の時の性能と比較すると少し高く見えます．\n",
    "\n",
    "ここで，この4種類の活性化関数のグラフを作ってみます（横軸が入力で，縦軸が関数の値）．\n",
    "様々な可視化は次回行いますが，とりあえず以下のセルを動かすとグラフが出てきます．\n",
    "グラフの作り方についてもう少しきちんと知りたい方は，day6_matplotlib.ipynbを見る・matplotlibで調べる等してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter lab/notebookの時のコマンド\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "x = 4*np.arange(100) / 100 - 2.0\n",
    "plt.plot(x, x, label=\"identity\") # identity\n",
    "plt.plot(x, 1.0 / (1.0 + np.exp(-x)), label=\"logistic\") # logistic\n",
    "plt.plot(x, np.tanh(x), label=\"tanh\") # tanh\n",
    "plt.plot(x, np.maximum(x, 0), label=\"relu\") # relu\n",
    "plt.legend(fontsize=12, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較的結果の悪かった`\"identity\"`と`\"relu\"`は非有界（=関数の値がどこまでも大きくなる or 小さくなる）ですが，（お世辞にも良い結果ではないですが）`\"logistic\"`と`\"tanh\"`は有界（前者は$(0, 1)$，後者は$(-1, 1)$）です．\n",
    "そのため，以下のようなことが起こっているのではないかと考えられます：**活性化関数に通す前の中間層の値が非常に大きくなってしまっているのではないか？**\n",
    "\n",
    "活性化関数に通す前の値は，「入力ベクトルと重み行列の積」によって計算されます．\n",
    "したがって，特徴ベクトルの値が大きい場合，中間層の値が非常に大きくなってしまう可能性があります．\n",
    "特徴ベクトルの値をちょっと思い出してみます．\n",
    "one-hotエンコーディングによって作られた部分は0か1でした．\n",
    "各サイズで売れた数を表す部分は，かなり大きな数字が入っていたような記憶があると思います．\n",
    "ちょっと見てみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_train)\n",
    "print(np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大で5ケタの大きな値が入っており，先程述べていたことが起こっている可能性が高そうに思えてきます．\n",
    "また，そもそも，特徴の値の最大値と最小値の範囲が，各特徴毎に大きく異なるというのは問題となることがあります．\n",
    "線形モデルの例を考えてみます．\n",
    "one-hotエンコーディングされたある特徴（たとえば，`\"ever_married\"`）の重みを$w_j$，数値として与えられたある特徴（たとえば，`id`）に関する重みを$w_i$とし，$w_j=w_i=0.01$であるとします．\n",
    "このとき，one-hotエンコーディングされたある特徴の重み$w_j=0.01$であることに大きな問題はなさそうです：$x_j$は最大でも$1$なので，$x_j=0$の場合と比較しても予測の値が$0.1$程度増えるだけです．\n",
    "一方で，売れた数に関する重み **$w_i=0.01$は問題が起こります**：$x_i$の値が，例えば上で出ている最大値`72940.0`のとき，$x_i=0$の場合と比較して，**予測の値がおよそ729も増えてしまいます**．\n",
    "つまり，各特徴に対応するパラメータ（上の例では，$w_j$や$w_i$）のスケールは，その特徴のスケールに応じて適切なものになっていなければなりません．\n",
    "\n",
    "[sklearnのニューラルネットワークに関する解説](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use)を見てみましょう．\n",
    "次のように書いてあります：\n",
    "\n",
    "> \"Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization.\"\n",
    "\n",
    "ようするに， **MLPは特徴のスケールに影響を受けやすいので，そこらへんはどうにかしなさい（例えば，各特徴の値が$[0, 1]$や$[-1, 1]$の範囲に入るようにであったり，平均が0で分散が1になるようにしなさい）** と言っています．\n",
    "このように，学習アルゴリズムに入れる前に，特徴量に対して何らかの変換を施すことを **前処理（preprocessing）** と言います（one-hotエンコーディングも前処理の一部であると言えるでしょう）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn.preprocessing`：sklearnの機能を使って特徴量のスケールを揃える\n",
    "\n",
    "さて，それでは上で言われているように，特徴ベクトルのスケールを揃えてみましょう．\n",
    "今回は各特徴量を`[0, 1]`の範囲に（=最小値が0で最大値が1になるように）スケーリングします．\n",
    "numpyの演算を使うことでも比較的簡単にできますが，ここではsklearnの機能を使うことにします．\n",
    "\n",
    "sklearnには`sklearn.preprocessing`というモジュールがあり，このモジュールの中に様々な前処理のための関数・クラスが用意されています．\n",
    "今回は，**最大値と最小値を揃えるスケーリング**を行いたいわけですが，これは`sklearn.preprocessing`の中の`MinMaxScaler`によって行うことができます．\n",
    "\n",
    "そこで，今回のQuizです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1\n",
    "[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)を使って，各特徴の値を[0,1]の範囲にスケーリングした訓練データ`X_train_scaled`を作成し，`X_train_scaled`を用いて`MLPClassifier()`の交差検証を行してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 以下を埋める\n",
    "\n",
    "\n",
    "X_train_scaled =  # ここを埋める\n",
    "\n",
    "# モデルを作成し，交差検証で評価\n",
    "mlp = MLPClassifier()\n",
    "scores = cross_validate(mlp, X_train_scaled, y_train, cv=5, \n",
    "                        scoring=\"roc_auc\",\n",
    "                        return_train_score=True)\n",
    "print(f\"交差検証の5回のスコア：{scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{np.mean(scores['test_score'])}\")\n",
    "\n",
    "print(f\"交差検証の5回の訓練スコア：{scores['train_score']}\")\n",
    "print(f\"交差検証の平均訓練スコア：{np.mean(scores['train_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアが改善しました！\n",
    "しかもまだ細かい交差検証はしていませんから，更に性能の向上を見込めます．\n",
    "\n",
    "交差検証をして良いパラメータを定めてみましょう．\n",
    "前回の復習も兼ねて，続けてクイズです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2\n",
    "`X_train_scaled`を訓練データの入力として，`MLPClassifier`のハイパーパラメータを`GridSearchCV`によってチューニングしてください．\n",
    "ここで，以下の2つのパラメータを次で示す範囲でチューニングすること：\n",
    "- `hidden_layer_sizes`：(1)中間層が一つでユニット数が100 (2)中間層が2つでユニット数がそれぞれ80\n",
    "- `activation`：(1) \"logistic\" (2) \"tanh\" (3) \"relu\"\n",
    "\n",
    "また，計算時間の削減のため反復数`max_iter`は100とし，乱数の初期SEEDを定める`random_state`は765としてください．交差検証の分割数は5，スコア関数は`\"roc_auc\"`とすること．\n",
    "そして最後に，最も良かったハイパーパラメータの組と，その時の交差検証のスコアを`print`してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = # ここを埋める\n",
    "params_grid = {} # ここを埋める\n",
    "# 以下を埋める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も良かったハイパーパラメータとその時のスコアについて，私の環境では以下の結果が得られました：\n",
    "\n",
    "```Python\n",
    "{'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
    "\n",
    "0.8328010747254228\n",
    "```\n",
    "\n",
    "この結果で得られたベストなモデルを使って予測結果を提出すると良いかもしれません．\n",
    "その際，**テストデータの変換を行うのを忘れる・変換の仕方を誤る**と，ひどいスコアとなってしまうためご注意ください．\n",
    "なお，上のチューニングはかなり粗く・雑に行っているので，より丁寧に行うことでより良いスコアが出る可能性は高いです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "- 多層パーセプトロン（MLP）：ニューラルネットワークの一種．（非線形な活性化関数を使った場合）非線形なモデルで，特徴ベクトルのスケールに影響を強く受ける．\n",
    "- 前処理のための関数やクラスは`sklearn.preprocessing`にある．最大値と最小値のスケーリングは`MinMaxScaler`で行うことができる．\n",
    "\n",
    "今回用いた`MinMaxScaler`以外にも前処理のクラス・関数は多数あるので，それらについても調べてみる・使ってみると良いかもしれません．\n",
    "また，具体的に名前を列挙することはしませんが，非線形なモデルは`MLPClassifier`以外にも多数あります．\n",
    "その中には，特徴ベクトルのスケールの影響を受けにくく，使いやすいモデルもあります．\n",
    "また，興味深いことに，カテゴリカル変数をそのまま扱える手法もあります（残念ながらsklearnの実装ではそうなっておらず，その手法に特化したライブラリを使う必要がありますが）．\n",
    "「どのような特徴を作るか」「どのような変換を施すか」「どのようなモデルを使うか」「どのようなハイパーパラメータにするか」を考えると，できることは山ほどあるので，是非色々試してみてください．\n",
    "\n",
    "さらに，ここ10年弱の深層学習ブームにより，ニューラルネットワークのライブラリが多数開発されています．\n",
    "それらを用いることでより自由に・柔軟にニューラルネットワークを（MLPを）構築することができます．\n",
    "それらについても興味があれば調べてみると良いかもしれません．\n",
    "\n",
    "今回は，予測モデルを構築する前の処理として，スケーリングを取り上げました．\n",
    "それ以外にも，例えば\n",
    "- 特徴選択（feature selection）：元の特徴量からいくつかの特徴量を選ぶ（特徴選択で作られた低次元ベクトルは，元の特徴ベクトルの部分ベクトル）\n",
    "- 特徴抽出（feature extraction）：元の特徴量を用いて新しく（低次元の）特徴量を作り出す（元の特徴ベクトルの部分ベクトルとは限らない）\n",
    "\n",
    "等の処理を行うと，性能が向上することもあります．\n",
    "これらはsklearnでは[sklearn.feature_selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)や[sklearn.decomposition](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)に実装されています．\n",
    "余裕がある方は試してみると良いかもしれません．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 付録：EDA（Exploratory Data Analysis, 探索的データ分析）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまで，いくつかの学習モデルと様々な処理（one-hotエンコーディング，欠損値処理，交差検証，ハイパーパラメータ探索など）について見てきました．紹介した以外にも数多くのモデルや処理が存在し，その中で「うまくいく」方法を見つけることがコンペでよいスコアを出すためには重要です．しかし，片っ端からありとあらゆる手法を試すのは時間的な制約（コンペの開催期間）から考えても難しいでしょう．したがって，コンペにおいては「うまくいきそうな」手法を優先的に試すことになると思います．このときの手法選択の手がかりをつかむための手法として **EDA（Exploratory Data Analysis, 探索的データ分析）** が挙げられます．\n",
    "\n",
    "EDAでは，与えられたデータの特徴をつかみます．具体的には，\n",
    "\n",
    "- どのようなデータ（種類，数）が与えられているか\n",
    "- 各データの分布，例えば最大値や最小値，平均値や分散はどうなっているか\n",
    "- 欠損値はどれほど存在するか\n",
    "- 説明変数どうし，あるいは説明変数と目的変数の間に相関はあるか\n",
    "\n",
    "といった情報を\n",
    "\n",
    "- 棒グラフ\n",
    "- 箱ひげ図\n",
    "- 散布図\n",
    "- 折れ線グラフ\n",
    "- ヒートマップ\n",
    "- ヒストグラム\n",
    "\n",
    "などの可視化手法を用いて可視化し，データに関する情報を得ることを狙いとします．これらの情報は，どのようなモデルや手法なら「うまくいきそうか」，またどのような処理を行うべきかの参考にすることができます．\n",
    "\n",
    "EDAは，適宜必要なコードを自分で書き行うこともできますが，自分で0からコードを書くのは大変かもしれません．\n",
    "最も楽な方法の一つとして，`pandas`の`pandas_profiling`（[ドキュメント](https://pandas-profiling.ydata.ai/docs/master/)）のような既存の可視化ツールを使用することが挙げられます．\n",
    "以下で、`pandas_profiling`の使用方法について説明します．\n",
    "\n",
    "例えば訓練データの情報を見たいとき，以下のように実行できます．\n",
    "\n",
    "（セルの実行中に`Proceed (y/n)?`のように聞かれた場合，`y`と回答してください．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabを使っている場合はこのセルを実行する（pandas_profiling, markupsafeのバージョンを更新）\n",
    "# 自身のPython環境を用いている場合、適宜インストールを行う\n",
    "!pip uninstall pandas_profiling\n",
    "!pip install -U pandas_profiling\n",
    "!pip install markupsafe==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "pandas_profiling.ProfileReport(pd.read_csv(\"data/train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のセルを実行すると，様々な情報が表示されると思います．こうした情報をもとにモデルや手法を探すことで，より良いスコアを狙うことができます．一般にコンペにおいては正解というものはありません．データと自分の直感とをすり合わせ，思い思いのモデルを作成してみてください．\n",
    "\n",
    "参考文献：「Kaggleで勝つデータ分析の技術」（2019，門脇大輔ほか，技術評論社）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from sklearn.preprocessing import MinMaxScaler`で使えるようになります．\n",
    "`MinMaxScaler`は，標準では[0,1]にスケーリングするため，特に引数の設定をすることなくインスタンスを作成します．\n",
    "ドキュメントを読んでみると分かりますが，`fit`メソッドで各特徴量の最大値と最小値を計算し，`transform`メソッドで変換を施した行列を返します．\n",
    "そのため，以下のようになります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 以下を埋める\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) # ここを埋める\n",
    "\n",
    "# モデルを作成し，交差検証で評価\n",
    "mlp = MLPClassifier()\n",
    "scores = cross_validate(mlp, X_train_scaled, y_train, cv=5, \n",
    "                        scoring=\"roc_auc\",\n",
    "                        return_train_score=True)\n",
    "print(f\"交差検証の5回のスコア：{scores['test_score']}\")\n",
    "print(f\"交差検証の平均スコア：{np.mean(scores['test_score'])}\")\n",
    "\n",
    "print(f\"交差検証の5回の訓練スコア：{scores['train_score']}\")\n",
    "print(f\"交差検証の平均訓練スコア：{np.mean(scores['train_score'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=100, random_state=765) # ここを埋める\n",
    "params_grid = {\n",
    "    \"hidden_layer_sizes\": [(100, ), (80, 80)],\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],} # ここを埋める\n",
    "# 以下を埋める\n",
    "cv = GridSearchCV(mlp, param_grid=params_grid, cv=5, scoring=\"roc_auc\")\n",
    "cv.fit(X_train_scaled, y_train)\n",
    "print(cv.best_params_) # 最も良かったハイパーパラメータを見てみる\n",
    "print(cv.best_score_) # 最も良かったハイパーパラメータの時のスコアを見てみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
