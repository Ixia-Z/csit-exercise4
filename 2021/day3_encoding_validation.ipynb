{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcfmVOR5ZpbT"
   },
   "source": [
    "# 「文字列情報のone-hotエンコーディング」と「検証用データを用いたモデルの評価」\n",
    "前回は以下のことを学びました．\n",
    " - pandasによるcsvの読み込みと簡単な操作（列・行へのアクセス，`numpy.ndarray`への変換）\n",
    " - sklearnの基本的な使い方\n",
    " - 提出までの流れ：\n",
    "   1. 特徴ベクトルの作成\n",
    "   2. モデル・アルゴリズムの選定，学習\n",
    "   3. 予測\n",
    "   4. 提出\n",
    "\n",
    "その一方で，以下のことは**行いませんでした**：\n",
    " - 文字列情報の利用：文字列で表現されている\"type\"や\"region\"，\"Date\"の情報はどうやって用いるのか？\n",
    " - 予測の投稿前の定量的な評価：バイアス項を用いない線型回帰`LinearRegression(fit_intercept=False)`は悪そうだが，本当に悪いのか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPiKpvGtZpbU"
   },
   "source": [
    "## 今回学ぶこと\n",
    " - 文字列情報のone-hotエンコーディング\n",
    " - 検証用データを用いたモデルの投稿前の評価\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nI89-u1ZpbV"
   },
   "source": [
    "## （復習）予測モデル構築の流れ\n",
    "\n",
    "機械学習を用いて予測モデルを構築し，未知の（テスト）データに対して予測を行う手順は，主に以下のようになります．\n",
    "1. データを用意し，特徴ベクトルを作る\n",
    "2. どのような手法（モデル）を使うかを決める\n",
    "3. モデルを学習する方法を決め，学習する\n",
    "4. 未知のデータに予測を行う（そして本演習では提出する）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvBYZMeNZpbV"
   },
   "source": [
    "## （復習）データ読み込み\n",
    "前回と同様に，まずはデータの読み込みを行います．\n",
    "データの読み込みはpandasの`read_csv`で行えます．\n",
    "ライブラリを使うためには`import`する必要があります．\n",
    "詳細は前回の資料を参照してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LinearRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0gicvqeZpbW"
   },
   "source": [
    "Colabの場合は次のセルを（コメントアウトを外して）動かし，更にその次のパスを適宜変更してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iGNrAnlNdW6P",
    "outputId": "adb30339-898f-4847-dfc6-d86dafaca3c6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive') # google driveをマウント（＝Colabから使えるようにする）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeJHyc4tZpba"
   },
   "outputs": [],
   "source": [
    "# 動的型付け言語なので，変数の型の宣言は不要\n",
    "d_train = pd.read_csv(\"data/train.csv\") # 訓練データを読み込む\n",
    "d_test = pd.read_csv(\"data/test.csv\") # テストデータを読み込む\n",
    "# Google Colabの場合\n",
    "#d_train = pd.read_csv(\"drive/My Drive/data/train.csv\") # 訓練データを読み込む．TFがGoogle Driveの一番上にdataディレクトリを置いた場合はこのようなパスになった\n",
    "#d_test = pd.read_csv(\"drive/My Drive/data/test.csv\") # テストデータを読み込む． TFがGoogle Driveの一番上にdataディレクトリを置いた場合はこのようなパスになった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYspsl3KZpbc"
   },
   "source": [
    "前回と同じように，読み込んだデータを表示して確認します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "Dd5r2xjhZpbc",
    "outputId": "dac4d3fb-25ee-4235-b19d-94ccd3949428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ\n",
      "             Date         4046         4225       4770  Small Bags  \\\n",
      "0      2017-04-23      1121.34      5184.26       0.00      888.21   \n",
      "1      2017-09-17   1582315.47   1095433.56   47072.46   863081.25   \n",
      "2      2017-11-05       141.41       794.48       0.00     5320.50   \n",
      "3      2016-01-24      5289.88       111.58       0.00     5096.27   \n",
      "4      2018-01-28  14551799.50  12119884.61  575974.74  9749412.19   \n",
      "...           ...          ...          ...        ...         ...   \n",
      "12769  2015-07-12      1639.19        49.62       0.00     3592.55   \n",
      "12770  2016-01-31      8791.51     58433.15       0.00     6581.99   \n",
      "12771  2018-01-21       613.65      1852.11       0.00     4083.63   \n",
      "12772  2016-07-31       553.48         5.70       0.00     4514.72   \n",
      "12773  2015-03-15    156506.22    160239.43   17300.74    58756.28   \n",
      "\n",
      "       Large Bags  XLarge Bags          type            region  AveragePrice  \n",
      "0         2717.94         0.00       organic          LasVegas          1.67  \n",
      "1       591149.15      2174.92  conventional              West          1.53  \n",
      "2         1452.69         0.00       organic      Indianapolis          1.48  \n",
      "3            6.67         0.00       organic           Houston          1.38  \n",
      "4      3041125.42    133444.38  conventional           TotalUS          1.09  \n",
      "...           ...          ...           ...               ...           ...  \n",
      "12769        0.00         0.00       organic           Orlando          1.89  \n",
      "12770    15767.67         0.00       organic        GreatLakes          1.45  \n",
      "12771     2428.58         0.00       organic          Columbus          1.50  \n",
      "12772      113.33         0.00       organic  NewOrleansMobile          1.41  \n",
      "12773        0.00         0.00  conventional          Portland          1.21  \n",
      "\n",
      "[12774 rows x 10 columns]\n",
      "\n",
      "テストデータ\n",
      "            Date       4046        4225      4770  Small Bags  Large Bags  \\\n",
      "0     2018-03-25   19823.16    58366.54    201.04   265716.88    30752.06   \n",
      "1     2015-05-24    2157.12   117543.69   3203.21    26280.32    31985.38   \n",
      "2     2016-01-10   82729.50    33601.78  17903.44    21493.26     6988.68   \n",
      "3     2016-08-14    2645.81    72836.99     71.45    37629.15        0.00   \n",
      "4     2018-01-07   40579.40    24117.63   1241.27    36998.30     7993.17   \n",
      "...          ...        ...         ...       ...         ...         ...   \n",
      "5470  2015-05-31     943.29        5.85      0.00     1142.28        0.00   \n",
      "5471  2015-12-13     592.64     2602.48      0.00      696.67      702.92   \n",
      "5472  2016-08-28    5636.60    15479.57      0.00      259.04      253.19   \n",
      "5473  2017-11-26  208161.00  1937090.00   6919.00   820402.00   296888.00   \n",
      "5474  2017-10-22    1240.60       10.63      0.00    10281.38        6.67   \n",
      "\n",
      "      XLarge Bags          type            region  \n",
      "0            0.00       organic         Northeast  \n",
      "1            0.00  conventional        Pittsburgh  \n",
      "2         1260.37  conventional          Columbus  \n",
      "3         1145.00  conventional  BuffaloRochester  \n",
      "4            0.00  conventional        Pittsburgh  \n",
      "...           ...           ...               ...  \n",
      "5470         0.00       organic             Tampa  \n",
      "5471         0.00       organic         Nashville  \n",
      "5472         0.00       organic          Portland  \n",
      "5473         0.00  conventional         Northeast  \n",
      "5474         0.00       organic        Pittsburgh  \n",
      "\n",
      "[5475 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練データ\")\n",
    "print(d_train)\n",
    "print(\"\\nテストデータ\")\n",
    "print(d_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7n7okSAnZpbm"
   },
   "source": [
    "前回と同様にいくつかの変数を用意します．\n",
    " - `n_train`, `n_test`：訓練データ数，テストデータ数.\n",
    " - `y_train`：訓練データの目標値．`pop`メソッドによって元のデータフレームから取り除いて作る．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "IdRqhaBCZpbm",
    "outputId": "9fd134ef-30db-4287-a6c7-1c771c67b803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データとテストデータの数を取得\n",
      "訓練データ数：12774，テストデータ数：5475\n",
      "\n",
      " 出力情報を取り出す．AveragePriceの列が消えている\n",
      "             Date         4046         4225       4770  Small Bags  \\\n",
      "0      2017-04-23      1121.34      5184.26       0.00      888.21   \n",
      "1      2017-09-17   1582315.47   1095433.56   47072.46   863081.25   \n",
      "2      2017-11-05       141.41       794.48       0.00     5320.50   \n",
      "3      2016-01-24      5289.88       111.58       0.00     5096.27   \n",
      "4      2018-01-28  14551799.50  12119884.61  575974.74  9749412.19   \n",
      "...           ...          ...          ...        ...         ...   \n",
      "12769  2015-07-12      1639.19        49.62       0.00     3592.55   \n",
      "12770  2016-01-31      8791.51     58433.15       0.00     6581.99   \n",
      "12771  2018-01-21       613.65      1852.11       0.00     4083.63   \n",
      "12772  2016-07-31       553.48         5.70       0.00     4514.72   \n",
      "12773  2015-03-15    156506.22    160239.43   17300.74    58756.28   \n",
      "\n",
      "       Large Bags  XLarge Bags          type            region  \n",
      "0         2717.94         0.00       organic          LasVegas  \n",
      "1       591149.15      2174.92  conventional              West  \n",
      "2         1452.69         0.00       organic      Indianapolis  \n",
      "3            6.67         0.00       organic           Houston  \n",
      "4      3041125.42    133444.38  conventional           TotalUS  \n",
      "...           ...          ...           ...               ...  \n",
      "12769        0.00         0.00       organic           Orlando  \n",
      "12770    15767.67         0.00       organic        GreatLakes  \n",
      "12771     2428.58         0.00       organic          Columbus  \n",
      "12772      113.33         0.00       organic  NewOrleansMobile  \n",
      "12773        0.00         0.00  conventional          Portland  \n",
      "\n",
      "[12774 rows x 9 columns]\n",
      "[1.67 1.53 1.48 ... 1.5  1.41 1.21]\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練データとテストデータの数を取得\")\n",
    "n_train = len(d_train)\n",
    "n_test = len(d_test)\n",
    "print(f\"訓練データ数：{n_train}，テストデータ数：{n_test}\")\n",
    "print(\"\\n 出力情報を取り出す．AveragePriceの列が消えている\")\n",
    "# targetの値\n",
    "y_train = d_train.pop('AveragePrice')\n",
    "y_train = y_train.values # numpyのarrayに変換\n",
    "print(d_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEcnW_TBZpbr"
   },
   "source": [
    "ここまで動かしてきたセルは今後の回でも毎回のように動かします．次回以降は説明を省略します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9d8mZ0s9Zpbr"
   },
   "source": [
    "## （復習）数値情報だけの特徴ベクトルを作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LV6gQ_N8Zpbs"
   },
   "source": [
    "またしても復習ですが，**まず**前回と同じ特徴ベクトルを作ります．\n",
    "入力の情報として，以下が与えられています：\n",
    " - Date：日付\n",
    " - 4046, 4225, 4770：小，大，特大として売れた数\n",
    " - Small Bags, Large Bags, XLarge Bags：小，大，特大の袋として売れた数\n",
    " - type：オーガニックか否か\n",
    " - region：地域\n",
    "\n",
    "この中で，\"Date\"，\"type\"，\"region\"が文字列（string)の情報です．\n",
    "前回はこれらを用いずに，\"4046\"，\"4225\"，\"4770\"，\"Small Bags\"，\"Large Bags\"，\"XLarge Bags\"の**元から数値的な情報である6つだけ**を用いました．\n",
    "pandasではブラケット（角括弧）`[]`を用いることで特定の列や行を取り出すことができ，また`.values`で配列の中身だけを取り出せるのでした．\n",
    "したがって，以下のようにすることで数値の情報だけを用いた特徴ベクトルの行列を作ることができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8jHiGdZZpbs"
   },
   "outputs": [],
   "source": [
    "columns_num = [\"4046\", \"4225\", \"4770\", \"Small Bags\", \"Large Bags\", \"XLarge Bags\"]\n",
    "X_train_num = d_train[columns_num].values\n",
    "X_test_num = d_test[columns_num].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （復習）線形回帰の学習と予測\n",
    "sklearnを用いる基本的な手順は，\n",
    "1. モデルのインスタンスを作成\n",
    "2. 作成したモデルオブジェクトを**`fit`メソッド**を用いて学習．`fit`メソッドには訓練データの入力と目標値（つまり，行列とベクトル）を渡す．\n",
    "3. 学習したモデルを用いて**`predict`メソッド**で予測．`predict`メソッドにはデータの入力（つまり行列）を渡す．\n",
    "\n",
    "でした．以下のようにして実行できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.42770035 1.42778589 1.41099591 ... 1.42480144 1.52284404 1.42431654]\n"
     ]
    }
   ],
   "source": [
    "# 手順1：LinearRegressionのインスタンスの作成\n",
    "lr = LinearRegression()\n",
    "# 手順2：上で作ったオブジェクトの学習\n",
    "lr.fit(X_train_num, y_train)\n",
    "# 手順3：テストデータに対する予測\n",
    "y_pred_test_lr = lr.predict(X_test_num)\n",
    "print(y_pred_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ついでに，**バイアス項を使わない**線形回帰も学習しておきます．\n",
    "インスタンスを作成する時に，`fit_intercept=False`とすればよいのでした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10116005  0.03665987 -0.00890221 ...  0.00281757  0.71213428\n",
      "  0.00324945]\n"
     ]
    }
   ],
   "source": [
    "# 手順1：LinearRegressionのインスタンスの作成．fit_intercept=Falseとすることで，バイアス項を使わない\n",
    "lr_without_bias = LinearRegression(fit_intercept=False)\n",
    "# 手順2：上で作ったオブジェクトの学習\n",
    "lr_without_bias.fit(X_train_num, y_train)\n",
    "# 手順3：テストデータに対する予測\n",
    "y_pred_test_lr_without_bias = lr_without_bias.predict(X_test_num)\n",
    "print(y_pred_test_lr_without_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SqDf0uWZpbx"
   },
   "source": [
    "これで最低限の準備は終了です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字列情報のone-hotエンコーディング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列情報である\"Date\"，\"type\"，\"region\"は，値段の予測に役に立つと考えられるのでやはり利用したいです．\n",
    "機械学習手法は基本的に数値情報しか用いることができないため，文字列の情報をどうにかして数値に変換する必要があります．\n",
    "一般に，非数値的な変数のことを**質的変数**や**カテゴリカル変数**と呼びます．\n",
    "\n",
    "一つの方法として，**文字列一つ一つに適当に数字（例えば0（or 1）から始まる整数値）を割り当てる**というのが考えられます．\n",
    "例えば，\"type\"では\"organic\"を1，\"conventional\"を2に変換する，\"region\"では\"LasVegas\"を1，\"West\"を2，\"Indiannapolis\"を3…，といった方法です．\n",
    "しかし，この方法は多くのケースでは適切ではありません．\n",
    "まず，基本的に，多くの予測モデルにおいて**特徴の値は重要な要素**です．\n",
    "例えば線形モデルは以下の式で与えられます：\n",
    "$$y(\\mathbf{x}; \\mathbf{w}) = \\sum_{j=1}^D x_jw_j.$$ \n",
    "$x_j$というのは$w_j$の係数になっていますから，$x_j$の絶対値が大きい時，$w_j$の予測結果に対する影響度は大きくなります．\n",
    "しかし，**文字列に割り当てた数字の値そのものに（基本的には）意味はない**はずです．\n",
    "\"LasVegas\"を2にして，\"West\"を1にしてもよいはずです．\n",
    "けれども，予測モデルに与えた時，数字の大きさが考慮されてしまいますから，この方法は適切ではないでしょう（したがって，**与えられたデータが数字で表現されていても，数字の値そのものに意味がない場合はそのまま使うのは適切ではない**ということになります）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列情報の数値的な情報への変換方法で最もメジャーな方法として**one-hotエンコーディング**があります．\n",
    "one-hotエンコーディングでは，**一つのカテゴリカル変数はカテゴリー数の次元のベクトルに変換**されます．\n",
    "変換されたベクトルは，一つの要素が一つのカテゴリに対応していて，対応する要素の値が1でそれ以外の要素の値が0であるようなベクトルです．\n",
    "\n",
    "例えば，\"region\"変数が\"LasVegas\"，\"West\"，\"Indianapolis\"，\"Houston\"の4種類の値を取ると仮定します（実際はもっと多いですが）．\n",
    "この時，これらの文字列はそれぞれ，以下のような4次元のベクトルに変換されます．\n",
    "- \"LasVegas\" -> $(1, 0, 0, 0)$\n",
    "- \"West\" -> $(0, 1, 0, 0)$\n",
    "- \"Indianapolis\" -> $(0, 0, 1, 0)$\n",
    "- \"Houston\" -> $(0, 0, 0, 1)$\n",
    "\n",
    "基本的に要素の対応関係は自由です（\"West\"と\"Indianapolis\"を入れ替えても良い）．\n",
    "質的変数を含むデータでは，全ての質的変数にこのような変換を施して，数値的（量的）なベクトルと全ての質的変数のone-hotベクトルを連結したベクトルを特徴ベクトルとして用いることが多いです．\n",
    "\n",
    "さて，この変換は適切なのでしょうか？\n",
    "質的変数にも色々ありますから，全ての質的変数をダミー変数にすることが適切であるとは限りませんが，少なくとも雑に整数値を割り当てるよりはずっと良いです．\n",
    "上の例の4次元ベクトルに対する線形モデルを例に考えてみます．\n",
    "線形モデルの式は$y(\\mathbf{x}; \\mathbf{w}) = \\sum_{j=1}^D x_jw_j$でした．\n",
    "$\\mathbf{x}$は今はどれか一つが$1$でそれ以外全てが$0$であるようなベクトルです．\n",
    "$x_j=0$の時，$w_j$は使われませんから，$w_j$はj番目の場所におけるアボカドの値段を表しています．\n",
    "$w_1$は\"LasVegas\"における値段の予測，$w_2$は\"West\"における値段の予測…といったようになり，雑に整数値を割り当てるよりはずっと良さそうですね．\n",
    "\n",
    "one-hotエンコーディングでは，それぞれのカテゴリに一つの要素を割り当てて，完全に異なる特徴として扱います．\n",
    "そのため，\"Date\"の例ですと，「日付が近い場合，値段の傾向も近い」と考えるのが自然かと思いますが，日付が異なれば完全に別のものとして扱うため，そのような傾向を陽に扱うことが難しくなります．\n",
    "ですが，今回はとりあえず全ての文字列情報をone-hotエンコードします．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandasによるone-hotエンコーディング\n",
    "それでは実際に\"Date\"，\"type\"，\"region\"の文字列情報をone-hotエンコーディングしてみましょう！\n",
    "一見すると「書けるけど確実にそこそこ面倒だな」と思うかもしれません．\n",
    "Pythonには辞書型という使いやすいハッシュテーブルが提供されていますが，それでも少し面倒かもしれません．\n",
    "幸運なことに，pandasには`get_dummies`という非常に便利な関数が用意されています．\n",
    "`get_dummies`を使うと，`DataFrame`の特定の列を簡単にone-hotエンコーディングできます．\n",
    "\n",
    "ここまで退屈だったと思いますので，今回のQuizです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1\n",
    "\n",
    "[get_dummiesのドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) を読んで，以下のセルを埋め，訓練データとテストデータの\"Date\"，\"type\"，\"region\"をone-hotエンコードしてください．\n",
    "**数値情報はone-hotエンコードせず，そのままにすること**．\n",
    "\n",
    "この時，訓練データとテストデータを別々にエンコードすると，訓練データとテストデータが異なるエンコードをされてしまう可能性があります（今回のデータに対して`get_dummies`を使った場合は起こりませんが）．\n",
    "そこで，**訓練データとテストデータを一旦連結**し，**連結したものをエンコード**し，**エンコード後に再び分ける**ことにします．\n",
    "以下のセルでは最初に訓練データとテストデータを連結させた`d_train_test`を作っています（上が`d_train`，下が`d_test`）．\n",
    "また，`columns_cat`はカテゴリカル変数の列名を集めたリストです．\n",
    "これらを利用すると楽でしょう（使わなくともよいですが）．\n",
    "訓練データとテストデータを分離させる方法については，前回の資料が参考になります．\n",
    "\n",
    "変換後の行列が**231次元になっていれば正しいです**．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_test = pd.concat([d_train, d_test], axis=0) # 訓練とテストを連結\n",
    "columns_cat = [\"Date\", \"type\", \"region\"] # カテゴリカル変数の列名\n",
    "\n",
    "d_train_test_onehot =　# ここを埋める．get_dummiesを使ってone-hotエンコーディング\n",
    "d_train_onehot = # ここを埋める．d_train_test_onehotの訓練データ部分\n",
    "d_test_onehot =  # ここを埋める．d_train_test_onehotのテストデータ部分\n",
    "X_train_onehot = d_train_onehot.values # np.arrayに変換\n",
    "X_test_onehot = d_test_onehot.values  # np.arrayに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`d_train_onehot`を`print`してみましょう．\n",
    "数値情報を全てそのまま使いつつ，列の数が増えていることが分かります．\n",
    "特に，`region_SouthCentral`のように`元のカテゴリ変数の名前_カテゴリ名`という名前の列名が増えていますね．\n",
    "名前から明らかですが，`C_c`という名前の列があったとすると，それは`C`というカテゴリカル変数の`c`という名前のカテゴリに対応しています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              4046         4225       4770  Small Bags  Large Bags  \\\n",
      "0          1121.34      5184.26       0.00      888.21     2717.94   \n",
      "1       1582315.47   1095433.56   47072.46   863081.25   591149.15   \n",
      "2           141.41       794.48       0.00     5320.50     1452.69   \n",
      "3          5289.88       111.58       0.00     5096.27        6.67   \n",
      "4      14551799.50  12119884.61  575974.74  9749412.19  3041125.42   \n",
      "...            ...          ...        ...         ...         ...   \n",
      "12769      1639.19        49.62       0.00     3592.55        0.00   \n",
      "12770      8791.51     58433.15       0.00     6581.99    15767.67   \n",
      "12771       613.65      1852.11       0.00     4083.63     2428.58   \n",
      "12772       553.48         5.70       0.00     4514.72      113.33   \n",
      "12773    156506.22    160239.43   17300.74    58756.28        0.00   \n",
      "\n",
      "       XLarge Bags  Date_2015-01-04  Date_2015-01-11  Date_2015-01-18  \\\n",
      "0             0.00                0                0                0   \n",
      "1          2174.92                0                0                0   \n",
      "2             0.00                0                0                0   \n",
      "3             0.00                0                0                0   \n",
      "4        133444.38                0                0                0   \n",
      "...            ...              ...              ...              ...   \n",
      "12769         0.00                0                0                0   \n",
      "12770         0.00                0                0                0   \n",
      "12771         0.00                0                0                0   \n",
      "12772         0.00                0                0                0   \n",
      "12773         0.00                0                0                0   \n",
      "\n",
      "       Date_2015-01-25  ...  region_SouthCarolina  region_SouthCentral  \\\n",
      "0                    0  ...                     0                    0   \n",
      "1                    0  ...                     0                    0   \n",
      "2                    0  ...                     0                    0   \n",
      "3                    0  ...                     0                    0   \n",
      "4                    0  ...                     0                    0   \n",
      "...                ...  ...                   ...                  ...   \n",
      "12769                0  ...                     0                    0   \n",
      "12770                0  ...                     0                    0   \n",
      "12771                0  ...                     0                    0   \n",
      "12772                0  ...                     0                    0   \n",
      "12773                0  ...                     0                    0   \n",
      "\n",
      "       region_Southeast  region_Spokane  region_StLouis  region_Syracuse  \\\n",
      "0                     0               0               0                0   \n",
      "1                     0               0               0                0   \n",
      "2                     0               0               0                0   \n",
      "3                     0               0               0                0   \n",
      "4                     0               0               0                0   \n",
      "...                 ...             ...             ...              ...   \n",
      "12769                 0               0               0                0   \n",
      "12770                 0               0               0                0   \n",
      "12771                 0               0               0                0   \n",
      "12772                 0               0               0                0   \n",
      "12773                 0               0               0                0   \n",
      "\n",
      "       region_Tampa  region_TotalUS  region_West  region_WestTexNewMexico  \n",
      "0                 0               0            0                        0  \n",
      "1                 0               0            1                        0  \n",
      "2                 0               0            0                        0  \n",
      "3                 0               0            0                        0  \n",
      "4                 0               1            0                        0  \n",
      "...             ...             ...          ...                      ...  \n",
      "12769             0               0            0                        0  \n",
      "12770             0               0            0                        0  \n",
      "12771             0               0            0                        0  \n",
      "12772             0               0            0                        0  \n",
      "12773             0               0            0                        0  \n",
      "\n",
      "[12774 rows x 231 columns]\n"
     ]
    }
   ],
   "source": [
    "print(d_train_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，新たに作った特徴ベクトルの行列を用いて線形回帰を学習し，結果を保存してみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.86508342 1.05907359 0.83719485 ... 1.5565368  1.47089209 1.8637187 ]\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_onehot, y_train) # 学習\n",
    "y_pred_test_lr_onehot = lr.predict(X_test_onehot)\n",
    "print(y_pred_test_lr_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ついでに，バイアス項なしの線形回帰も学習し，その結果を保存しておきましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.81557459 1.10866466 0.82345937 ... 1.57020038 1.44596604 1.87548053]\n"
     ]
    }
   ],
   "source": [
    "lr_without_bias.fit(X_train_onehot, y_train) # 学習\n",
    "y_pred_test_lr_onehot_without_bias = lr_without_bias.predict(X_test_onehot)\n",
    "print(y_pred_test_lr_onehot_without_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値的な情報のみを用いた場合と比べ，結果がかなり変わっていますね！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVKtGgAyZpby"
   },
   "source": [
    "## 検証用データを用いたモデルの評価\n",
    "### 過学習\n",
    "さて，これまでの手順でひとまず２つのモデルと２つの特徴表現が得られ，合計4つの予測結果を作成しました．\n",
    "`LinearRegression`のドキュメントを見れば分かりますが，他にも`normalize`というユーザが設定できる項目があります．\n",
    "これを`True`と`False`の2通りで試すと，もうそれだけで8種類の予測結果になってしまいます．\n",
    "しかし，一日の投稿回数が5回に制限されているため，全てのパターンを一日に投稿することはできません．\n",
    "他にも多数の予測手法がありますし，今後，**試行錯誤する要素はどんどん増加するため，毎回の予測結果を全て投稿して評価することは現実的ではありません**．\n",
    "そこで，**投稿せずに・投稿する前に**モデルを評価することを考えます．\n",
    "投稿する前にモデルの評価をして，悪そうなモデルの予測結果は投稿せず，良さそうな場合だけ投稿する，というのは妥当な戦略でしょう．\n",
    "また，コンペに限らず，モデルの事前の評価は機械学習手法の運用において常に非常に重要です．\n",
    "機械学習を用いたサービスを考えた時に，とりあえず作ってみた予測モデルを本番環境で動かしてみるのは恐ろしいことでしょう．\n",
    "本番環境で動かす前に一度評価して，良さそうであれば本番環境で動かすべきであるはずです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて，それではどのように投稿せずに・投稿する前にモデルを評価すれば良いのでしょうか？\n",
    "コンペのスコアは**予測と正解**を用いて計算されます（今回は平均二乗誤差）．\n",
    "残念ながら，テストデータの正解はわかっていないので，実際にコンペサイトから返ってくるスコアと同じものを事前に計算することはできません．\n",
    "そこで，正解がわかっているデータ，すなわち訓練データについて予測を行って，誤差を計算して性能を見積もる，というのが考えられます．\n",
    "しかし，この方法には問題があります．\n",
    "モデルは**訓練データの誤差を小さくするように学習**しています．\n",
    "非常に複雑なモデルを用いた時，訓練データに対する誤差をとにかく小さくしようとして（複雑なため，そのようなことが可能），その結果，訓練データに対して非常に精度の良い予測を行うが，訓練データに含まれないデータに対しては精度の低い予測を行ってしまう，ということがあります．\n",
    "このような現象・状態を**過学習・過適合（overfitting）**と言います．データサイエンスの初回の講義で登場した**次数の大きい多項式回帰**が過学習の良い例です．\n",
    "過学習するモデルというのは驚くほど簡単に作れてしまうため，**訓練データに対する誤差を用いてモデルを評価することは不適切です**．\n",
    "\n",
    "例えば，以下のセルを動かしてみましょう（少し時間を要するかもしれません）．\n",
    "以下のセルでは，過学習させるようにハイパーパラメータを選んだ**カーネルリッジ回帰**というモデルを動かしています（どのようなモデルかは今は気にしなくて良いです）．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge # カーネルリッジ回帰を使えるようにする\n",
    "kr = KernelRidge(kernel=\"rbf\", gamma=1.0, alpha=0.0001)\n",
    "kr.fit(X_train_num, y_train)\n",
    "y_pred_train_kr = kr.predict(X_train_num) # 訓練データに対して予測\n",
    "y_pred_test_kr = kr.predict(X_test_num) # テストデータに対して予測\n",
    "np.savetxt(X=y_pred_test_kr, fname=\"y_pred_kr.txt\") # テストデータの結果を保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，カーネルリッジ回帰の訓練データに対する予測`y_pred_train_kr`と訓練データの目標値`y_train`の間で平均二乗誤差を計算してみます．\n",
    "自分で実装しても良いですが，sklearnに`mean_squared_error`という名前で既に実装されています．\n",
    "以下のようにimportして使います．\n",
    "詳しくは[ドキュメント](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)を読んでみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カーネルリッジ回帰の訓練誤差：2.1406179554402282e-08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train_kr = mean_squared_error(y_train, y_pred_train_kr) # 最初の引数に目標値（正解），次に予測を入れるとスコアが返ってくる\n",
    "print(f\"カーネルリッジ回帰の訓練誤差：{mse_train_kr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e-08は10のマイナス8乗を意味していますから，これはもう**訓練データに対してはほとんど完全に正しく予測している**と言って良いでしょう．しかし，最後に\"y_pred_kr.txt\"としてファイル出力したテストデータに対する予測結果を実際に投稿してみると，**2.0前後の非常に悪いスコア（単にスコアの比を見ると，訓練データのおよそ100000000倍悪い！）**となっているはずです（信じがたい方はぜひ投稿してみてください）．\n",
    "\n",
    "繰り返しになりますが，この例からもわかるように，学習に用いたデータで評価することは適切ではありません．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証データの作成と検証データを用いた評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習に使ったデータでモデルを評価するのは不適切でした．\n",
    "そこで，正解のわかっているデータの一部を**学習には用いず検証（評価）に用いる**ということを行います．\n",
    "このようなデータを訓練データ（訓練集合）に対して**検証データ（検証集合，validation data, validation set)**と言います．\n",
    "\n",
    "では実際にデータの分割をしてみましょう．\n",
    "まず，数値情報だけを用いた`X_num`について行ってみます．\n",
    "とりあえずここでは，ラベル付きデータ全体のおよそ**8割を訓練データ，残りを検証用**とします．\n",
    "特に，現在のラベル付きデータの前半8割を訓練データ，後ろの2割を検証データとします．\n",
    "先程のQuiz 1では`DataFrame`の分割を行いましたが，`np.array`の分割も同様に行うことができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid= int(0.2*n_train) # 検証データの数．ラベル付きデータ数n_trainの2割を検証データにする\n",
    "n_train = n_train - n_valid # 訓練データ数を計算し直す．検証データ以外全てなので，全体（n_train)からn_validationを引く \n",
    "X_valid_num = X_train_num[n_train:] # 現在のX_train_numの後半2割 = 前半8割以降\n",
    "X_train_num = X_train_num[:n_train] # 現在のX_train_numの前半8割．再代入する（変数名を使い回す）\n",
    "\n",
    "# 目標値も同じように分割する\n",
    "y_valid = y_train[n_train:]\n",
    "y_train = y_train[:n_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，バイアス項ありの線形回帰，なしの線形回帰，さきほどのカーネルリッジ回帰の3種類のモデルを，分割した訓練データで学習し，検証データで評価してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数値情報・バイアス項ありの線形回帰：0.15152249165616682\n",
      "数値情報・バイアス項なしの線形回帰：2.0289021335715995\n",
      "数値情報・カーネルリッジ回帰：2.1083119420516834\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_num, y_train)\n",
    "y_pred_valid_lr = lr.predict(X_valid_num)\n",
    "mse_valid_lr = mean_squared_error(y_valid, y_pred_valid_lr)\n",
    "print(f\"数値情報・バイアス項ありの線形回帰：{mse_valid_lr}\")\n",
    "\n",
    "lr_without_bias.fit(X_train_num, y_train)\n",
    "y_pred_valid_lr_without_bias = lr_without_bias.predict(X_valid_num)\n",
    "mse_valid_lr_without_bias = mean_squared_error(y_valid, y_pred_valid_lr_without_bias)\n",
    "print(f\"数値情報・バイアス項なしの線形回帰：{mse_valid_lr_without_bias}\")\n",
    "\n",
    "# カーネルリッジ回帰の学習・評価\n",
    "kr.fit(X_train_num, y_train)\n",
    "y_pred_valid_kr = kr.predict(X_valid_num)\n",
    "mse_valid_kr = mean_squared_error(y_valid, y_pred_valid_kr)\n",
    "print(f\"数値情報・カーネルリッジ回帰：{mse_valid_kr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果が出てきました．\n",
    "カーネルリッジ回帰は訓練データに対する予測性能は良かったですが，訓練に使っていない検証データに対する予測性能が非常に悪い，教科書に載せたいような過学習の例となっていますね．\n",
    "また，バイアス項を使わない線形回帰に対しては，予想通り低いスコアとなっています．\n",
    "\n",
    "同様に，今回作ったone-hotベクトルに対しても訓練・検証の分割を行ってみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_onehot = X_train_onehot[n_train:] # 現在のX_train_onehotの後半2割 = 前半8割以降\n",
    "X_train_onehot = X_train_onehot[:n_train] # 現在のX_train_onehotの前半8割．再代入する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じように学習と評価を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数値情報+one-hot・バイアス項ありの線形回帰：0.05488747218517086\n",
      "数値情報+one-hot・バイアス項なしの線形回帰：0.054937524752930116\n",
      "数値情報+one-hot・カーネルリッジ回帰：2.1083119420516834\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_onehot, y_train)\n",
    "y_pred_valid_lr_onehot = lr.predict(X_valid_onehot)\n",
    "mse_valid_lr_onehot = mean_squared_error(y_valid, y_pred_valid_lr_onehot)\n",
    "print(f\"数値情報+one-hot・バイアス項ありの線形回帰：{mse_valid_lr_onehot}\")\n",
    "\n",
    "lr_without_bias.fit(X_train_onehot, y_train)\n",
    "y_pred_valid_lr_without_bias_onehot = lr_without_bias.predict(X_valid_onehot)\n",
    "mse_valid_lr_without_bias_onehot = mean_squared_error(y_valid, y_pred_valid_lr_without_bias_onehot)\n",
    "print(f\"数値情報+one-hot・バイアス項なしの線形回帰：{mse_valid_lr_without_bias_onehot}\")\n",
    "\n",
    "# カーネルリッジ回帰の学習・評価\n",
    "kr.fit(X_train_onehot, y_train)\n",
    "y_pred_valid_kr_onehot = kr.predict(X_valid_onehot)\n",
    "mse_valid_kr_onehot = mean_squared_error(y_valid, y_pred_valid_kr_onehot)\n",
    "print(f\"数値情報+one-hot・カーネルリッジ回帰：{mse_valid_kr_onehot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰は非常に良くなっていますね！\n",
    "また，one-hotベクトルも用いた場合，バイアス項の有無でほとんど差がありません．\n",
    "one-hotベクトルがどのようなものかを考えるとなんとなく理由がわかるかもしれません．\n",
    "\n",
    "一方，カーネルリッジ回帰は相変わらずひどいスコアです．\n",
    "ただ，これはカーネルリッジ回帰が悪いのではなく，カーネルリッジ回帰の**使い方**が悪いです．\n",
    "今後の資料では，使うのがやや難しいモデルをちゃんと使う，ということも行う予定です（線形回帰・カーネルリッジ回帰以外にも手法は色々あるので，ぜひ自身で調べて使ってみてください）．\n",
    "\n",
    "この結果を見て，ようやく安心して**one-hotエンコーディングが上手く働いている**と言えます．\n",
    "この線形回帰でテストデータの予測を計算して，自信を持って投稿してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-vIgkJLZpb4"
   },
   "outputs": [],
   "source": [
    "y_pred_test_lr_onehot = lr.predict(X_test_onehot)\n",
    "np.savetxt(X=y_pred_test_lr_onehot, fname='y_pred_lr_onehot.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はとりあえず前半8割を訓練，後半2割を検証としました．\n",
    "しかし，分割の仕方によって結果も変わってしまいます．\n",
    "分割・検証とハイパーパラメータの決定のもう少し賢い・便利な方法を次回行います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsEO5dR4Zpb-"
   },
   "source": [
    "## まとめ\n",
    " - 質的（カテゴリカル）データを変換する方法としてone-hotエンコーディングがある．一つ一つのカテゴリに特徴を割り当てて，そのカテゴリかそうでないかを0/1で表す．\n",
    " - 予測モデルを実際に使う前に（予測を提出する前に）モデルの評価をする必要がある．ラベルのある（もともと訓練用として渡されている）データを，訓練用のデータと検証用のデータに分割し，分割された訓練データだけを用いて学習し，学習に用いなかった検証用のデータを用いてモデルの評価をする．\n",
    " \n",
    " \n",
    "量的変数と質的変数（カテゴリカルデータ）について，例えば「名義尺度」「順序尺度」「間隔尺度」等で調べてみると細かい分類やどのような操作が意味を持つのか（持たないのか）が出てくると思うので，興味がある方は調べてみると良いと思います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WedY7N7ZpcG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDMa9eQfZpcI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXr9itgmZpcK"
   },
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "669YHjN7ZpcK"
   },
   "source": [
    "### Quiz 1\n",
    "`pd.get_dummies`で`get_dummies`を呼び出すことができます．\n",
    "最初の引数にone-hotエンコードを行う`DataFrame`を渡すので，`pd.get_dummies(d_train_test)`とすれば，とりあえずone-hotエンコードができます．\n",
    "今，`columns_cat`に含まれる列だけone-hotエンコードをしたいです．\n",
    "これは`columns`という名前の引数に`columns_cat`を指定することで可能になります．\n",
    "したがって，`pd.get_dummies(d_train_test, columns=columns_cat)`とすればよいです．\n",
    "\n",
    "次に，訓練とテストの取り出し方についてです\n",
    "`DataFrame`において`[i:j]`とすることで，`i`番目から`j-1`番目までの行をを取り出すことができます．\n",
    "また，`[:i]`とすることで`i-1`番目まで，`[i:]`とすることで`i`番目以降の行をを取り出すことができます．\n",
    "したがって，`d_train_test[:n_train]`とすることで訓練データを，`d_train_test[n_train:]`とすることでテストデータを取り出せます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5kZ3j5fZpcL"
   },
   "outputs": [],
   "source": [
    "d_train_test = pd.concat([d_train, d_test], axis=0) # 訓練とテストを連結\n",
    "columns_cat = [\"Date\", \"type\", \"region\"] # カテゴリカル変数の列名\n",
    "\n",
    "d_train_test_onehot = pd.get_dummies(d_train_test, columns=columns_cat) # ここを埋める．get_dummiesを使ってone-hotエンコーディング\n",
    "d_train_onehot = d_train_test_onehot[:n_train] # ここを埋める．d_train_test_onehotの訓練データ部分\n",
    "d_test_onehot = d_train_test_onehot[n_train:] # ここを埋める．d_train_test_onehotのテストデータ部分\n",
    "X_train_onehot = d_train_onehot.values # np.arrayに変換\n",
    "X_test_onehot = d_test_onehot.values  # np.arrayに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q99oC3o7ZpcN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KEcnW_TBZpbr"
   ],
   "name": "day2_linear_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
